{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Step--1\n",
    "###################################################################################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from flask import Flask, render_template\n",
    "# from flask_restplus import Api, Resource\n",
    "import os\n",
    "import re\n",
    "# from difflib import SequenceMatcher\n",
    "import nltk\n",
    "# nltk.download()\n",
    "import string\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "###################################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset (Knowledge base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Step--2\n",
    "###################################################################################################\n",
    "os.chdir(\"D:/Soliton/Soliton Work/previous work/Problems/\")\n",
    "data=pd.read_excel('ECQ_Meditech/Dictionary (eCQM).xlsx')\n",
    "df=pd.DataFrame(data)\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work -- Text Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Step--3\n",
    "###################################################################################################\n",
    "exclude = set(string.punctuation)\n",
    "#----------------------------------remove punctuation---------------\n",
    "\n",
    "def remove_punctuation(x):\n",
    "    \"\"\"\n",
    "    Helper function to remove punctuation from a string\n",
    "    x: any string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x = ''.join(ch for ch in x if ch not in exclude)\n",
    "    except:\n",
    "        pass\n",
    "    return x\n",
    "prob_data= df['ProblemDisplayName'].apply(remove_punctuation)\n",
    "\n",
    "prob_data=prob_data.astype(str).str.lower()\n",
    "#----------------------------------remove punctuation END---------------\n",
    "stopwords=['-on-','-','in','at','on','and','with','of','to','diabetic','other','unspecified','disorder','procedure',\n",
    "           'finding','uti','views','view','vw','mri','mr','nm',\n",
    "          'ip','note','ir','ext','vas','(',')','ap','y','[',']','pa','v',\n",
    "#           ] \n",
    "           'due','arf','r','ckd',\n",
    "           'alc','chf','cva','esrd','dvt','paf','h/o','bmi',\n",
    "           's/p','hx','pe','sebsequent','very','hrt','rvr','tia','situation','severe',]\n",
    "\n",
    "#-------Text normalization--------\n",
    "\n",
    "problem_data = []\n",
    "for a in prob_data:\n",
    "    text1 = a.split()\n",
    "    ################---text1 Processing----------\n",
    "    text1 = \" \".join(text1)\n",
    "    text1=text1.replace('1','one')\n",
    "    text1=text1.replace('2','two')\n",
    "    text1=text1.replace('3','three')\n",
    "    text1=text1.replace('4','four')\n",
    "    text1=text1.replace('5','five')\n",
    "    text1=text1.replace('6','six')\n",
    "    text1=text1.replace('7','seven')\n",
    "    text1=text1.replace('8','eight')\n",
    "    text1=text1.replace('9','nine')\n",
    "    text1=text1.replace('0','zero')\n",
    "    text1=text1.replace('15','fifteen')\n",
    "#     text1=text1.replace('%2F','/')\n",
    "    text_tokens = word_tokenize(str(text1))\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords]\n",
    "    text1 = (\" \").join(tokens_without_sw)\n",
    "    problem_data.append(text1)\n",
    "###################################################################################################\n",
    "print(\"---Run---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work -- String Matching with Fuzzy Logics using Client (testing) Problem and return the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--step--4\n",
    "def get_data(ProblemDisplayName):\n",
    "    import time\n",
    "    t0=time.time()\n",
    "    lis=[]\n",
    "    result={}\n",
    "    problem=[]\n",
    "    Client_problem= remove_punctuation(ProblemDisplayName)\n",
    "    Client_problem=Client_problem.lower()\n",
    "    data = Client_problem.split()\n",
    "    ################---text1 Processing----------\n",
    "    data = \" \".join(data)\n",
    "    data=data.replace('1','one')\n",
    "    data=data.replace('2','two')\n",
    "    data=data.replace('3','three')\n",
    "    data=data.replace('4','four')\n",
    "    data=data.replace('5','five')\n",
    "    data=data.replace('6','six')\n",
    "    data=data.replace('7','seven')\n",
    "    data=data.replace('8','eight')\n",
    "    data=data.replace('9','nine')\n",
    "    data=data.replace('0','zero')\n",
    "    data=data.replace('15','fifteen')\n",
    "    data=data.replace('single','one')\n",
    "    data=data.replace('sinus','Sinuses')\n",
    "    data=data.replace('arteries','artery')        \n",
    "    data=data.replace('venous','vein')        \n",
    "    data=data.replace('arches','arch')\n",
    "    data=data.replace('bilat','bilateral')    \n",
    "    data=data.replace('arterial','artery')  \n",
    "    data=data.replace('bones','bone')\n",
    "    data=data.replace('feet','foot')\n",
    "    data=data.replace('2f','-')\n",
    "    data=data.replace('/','')\n",
    "    text_tokens1 = word_tokenize(str(data))\n",
    "    tokens_without_sw1 = [word for word in text_tokens1 if not word in stopwords]\n",
    "    data = (\" \").join(tokens_without_sw1)\n",
    "    problem.append(data)\n",
    "#     print(problem)\n",
    "    count=0 \n",
    "    for cp in problem:\n",
    "        data=cp.split()\n",
    "        data.sort()   \n",
    "        client_prob=\" \".join(data)\n",
    "    for data1 in problem_data:\n",
    "        data1=data1.split(\" \")\n",
    "        data1.sort()\n",
    "        data1=\" \".join(data1)\n",
    "        count=count+1\n",
    "        res=fuzz.ratio(client_prob,data1)\n",
    "#         len_res=len(str(res))\n",
    "        if res>=100:\n",
    "#              result[res]=count\n",
    "# #         print(result1)\n",
    "# #         print(\"length:\",res_len)\n",
    "#     if len(result)>0:  \n",
    "#         max_key1=max(result)\n",
    "#         for key, val in result.items():\n",
    "#             if key==max_key1:\n",
    "            index2=(count-1)\n",
    "            Code=df['ProblemCode'][index2]\n",
    "            CodeSystem=df['ProblemCodeSystemName'][index2]\n",
    "            EnterProblem=Client_problem\n",
    "            FindingProblem= df['ProblemDisplayName'][index2]\n",
    "            Result=res\n",
    "            t1=time.time()\n",
    "            lis.append(Code)\n",
    "            lis.append(CodeSystem)\n",
    "            lis.append(EnterProblem)\n",
    "            lis.append(FindingProblem)\n",
    "            lis.append(t1-t0)\n",
    "    return lis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Swagger API store and Display the Resutls with Swagger Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Step--5    ----Problem----\n",
    "from flask import Flask\n",
    "from flask_restplus import Api, Resource\n",
    "flask_app = Flask(__name__)\n",
    "api = Api(app = flask_app)\n",
    "###################################################################################################\n",
    "name_space = api.namespace('Persivia-APP', description='Web Service to Codified Non Codify Data')\n",
    "@name_space.route(\"/Problem/v1/<string:ProblemDisplayName>\")\n",
    "class MainClass1(Resource):\n",
    "    def get(self, ProblemDisplayName):\n",
    "        data=get_data(ProblemDisplayName)\n",
    "        if data:\n",
    "            return{\n",
    "    #         \"Status\": \"Got the Problem results..!\",\n",
    "            'ProvidedDisplayName':data[2],'DisplayName':data[3],'code':data[0],'CodeSystem':data[1],'Response TIme':data[4] }\n",
    "        else:\n",
    "            return \"null\"\n",
    "              \n",
    "if __name__ == '__main__':\n",
    "    flask_app.run(port=7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
